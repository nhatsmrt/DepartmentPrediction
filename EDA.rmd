---
title: "Exploring Data"
author: "Nhat Pham"
output:
  html_notebook: default
  html_document: default
---
```{r, include = FALSE}
## https://www.r-graph-gallery.com/248-igraph-plotting-parameters/
library(igraph)
library(dplyr)
library(HiveR)
```

## Introduction and Simple Processing

```{r}
df_edges_list <- read.csv("./Data/edges_list.csv")
df_labels <- read.csv("./Data/department_labels.csv")
df_edges_list <- df_edges_list + 1
df_labels <- df_labels + 1

graph <- graph_from_data_frame(df_edges_list, directed = TRUE)
V(graph)[df_labels %>% select("id") %>% pull()]$true_department <- df_labels %>% 
  select("department_id") %>% 
  pull()

test_idx <- sample(df_labels$id, 0.2 * nrow(df_labels))
df_labels[test_idx, "department_id"] <- -1
V(graph)[df_labels %>% select("id") %>% pull()]$department <- df_labels %>% 
  select("department_id") %>% 
  pull()

```

```{r}
graph <- graph %>% simplify()
isolated <- which(degree(graph) == 0)
graph_simplified <- delete.vertices(graph, isolated)
```

## Visualization
### "Hairball" Plot
As the graph is too big, we will be content with visualizing a random subgraph of it:

```{r}
sampled_nodes <- sample(V(graph_simplified), 100, replace=F)
subgraph <- induced_subgraph(graph_simplified, sampled_nodes)
```


```{r fig.width=2, fig.height=2}
plot(
  subgraph,
  vertex.label = NA,
  layout = layout.auto(subgraph),
  vertex.size = 3, edge.arrow.size = 0.01,
  vertex.color = vertex_attr(subgraph, 'department')
)
```

### Hive Plots:
```{r}
hive = edge2HPD(
  df_edges_list %>% mutate(weight = rep(1, gsize(graph)))
)
plotHive(hive)
```


## Graph Statistics
Now let us look at some statistics of the graphs:

- *Diameter of the graph*: `r diameter(graph)`
- *Maximum degree*: `r max(degree(graph, mode = "all"))`. Maximum out-degree: `r max(degree(graph, mode = "out"))`. Maximum in-degree: `r max(degree(graph, mode = "in"))`
- *Average path length of the graph*: `r mean_distance(graph, directed = TRUE)`
- *Density of graph*: `r edge_density(graph)`
- *Global transitivity of the graph*: `r transitivity(graph)`
- *Reciprocity* (percentage of edges that are symmetrical): `r reciprocity(graph)`

The high reciprocity suggests that most correspondents are two ways: if a research sends an email to another, it is very likely that he/she will receive a reply.
<br>
Now, let us compare this statistics with that of random graphs with similar number of edges (and density). For instance, let us generate a thousand of such graphs and draw the histogram of their average path lengths:
```{r}
gl <- vector('list', 1000)
for (i in 1:1000) {
  gl[[i]] <- erdos.renyi.game(n = gorder(graph), p.or.m = edge_density(graph), type = "gnp")
}

gl_apls <- unlist(lapply(gl, mean_distance, directed = TRUE))

hist(
  gl_apls,
  xlim = range(c(2.45, 2.70)),
  main = "Histogram of Average Path Lengths",
  xlab = "Average Path Lengths",
  col = "blue"
)
abline(v = mean_distance(graph, directed = TRUE), col = "red", lty = 3, lwd = 2)
```

As we can see, the average path length of the graph is relatively higher than graphs with similar number of edges and density.
We can also compute some statistics of the nodes:

```{r}
between_centrality <- betweenness(graph, V(graph), normalized = TRUE)
```
## Community Detection (Unsupervised)

Here, we will apply some built-in unsupervised community detection methods provided by the igraph package.
### Fast-Greedy
The first one we will examine is the fast-greedy method:
```{r}
community_fg <- fastgreedy.community(as.undirected(graph))
```
Some statistics of the result:

- *Number of communities*: `r length(community_fg)`
- *Sizes of the communities*: `r sizes(community_fg)`

If we look at the breakdown of the values:
```{r}
table(sizes(community_fg))
```
We can see that the majority of the communities only have 1 members (i.e isolated). Some larger communities have up too more than 300 members!
<br>
The membership of each vertex can be found via:
```{r}
membership_fg <- membership(community_fg)
V(graph)$membership_fg <- membership_fg
```

```{r}
plot(community_fg, graph, vertex.label = NA,
  vertex.size = 3, edge.arrow.size = 0.01,
  vertex.color = vertex_attr(subgraph, 'department')
)
```

### Leading Eigenvector:
Now let us apply the edge-betweenness method:
```{r}
community_le <- leading.eigenvector.community(as.undirected(graph))
V(graph)$membership_le <- membership(community_le)
```
Some statistics of the result:

- *Number of communities*: `r length(community_le)`
- *Sizes of the communities*: `r sizes(community_le)`

Again, looking at the breakdown of the values:
```{r}
table(sizes(community_le))
```
We see that the number of isolated communities have decreased, and the larger communities are also less extreme.
<br>
This seems like a more plausible representation of the true community structure.

### Random Walk:
```{r}
community_rw <- cluster_walktrap(graph)
V(graph)$membership_rw <- membership(community_rw)
```



### Louvain Algorithm:
```{r}
community_lv <- cluster_louvain(as.undirected(graph))
membership_lv <- membership(community_lv)
length(community_lv)
V(graph)$membership_lv <- membership(community_lv)
```


### Comparing results
Let us now compare the results of the algorithms. The lower the score, the more similar the results:

- *Fast Greedy v.s Leading Eigenvector*: `r compare(community_fg, community_le)`
- *Fast Greedy v.s Random Walk*: `r compare(community_fg, community_rw)`
- *Fast Greedy v.s Louvain*: `r compare(community_fg, community_lv)`

## Graphlet

## Homophily Analysis

## Extracting Vertices Feature
Now let us extract the features of the vertices.

### Simple Features:
We will extract the degree (first and second order) of each vertex, along with the number of triangles it belongs to:
```{r}
V(graph)$degree <- degree(graph)
V(graph)$degreeSecond <- neighborhood.size(graph, 2) / length(V(graph) - 1)
V(graph)$triangles <- count_triangles(graph)
V(graph)$local_transitivity <- transitivity(graph, type = "local", isolates = "zero")
```

### Centrality Features:
The next set of features are the centrality measures of each node:
```{r}
V(graph)$betweenness <- betweenness(graph, directed = TRUE)
V(graph)$eigenCentrality <- eigen_centrality(graph, directed = TRUE, scale = TRUE)$vector
V(graph)$closeness <- closeness(graph)
```
### Link-Based Features:
First, we compute the first and second order adjacency matrix, which will allow us to compute other link-based features:
```{r}
adj_mat <- as_adjacency_matrix(graph)
second_ord_adj_mat <- adj_mat %*% adj_mat
second_ord_adj_mat <- (second_ord_adj_mat > 0) + 0
diag(second_ord_adj_mat) <- 0
```
The first set of features we want to compute is the average degree, number of triangles, transitivity, and betweenness centrality of each node's first and second order neighborhood:
```{r}
V(graph)$avgDeg <- as.vector(adj_mat %*% V(graph)$degree) / V(graph)$degree
V(graph)$avgTriag <- as.vector(adj_mat %*% V(graph)$triangles) / V(graph)$degree
V(graph)$avgTransit <- as.vector(adj_mat %*% V(graph)$local_transitivity) / V(graph)$degree
V(graph)$avgBetween <- as.vector(adj_mat %*% V(graph)$betweenness) / V(graph)$degree
```

The next set of features are pagerank features. We also compute the personalized version with respect to each of the community relations we have found in the previous section:
```{r}
V(graph)$pr <- page.rank(graph)$vector
for (i in 1:42) {
  graph <- set_vertex_attr(graph, paste0("perpr_", i), value = page.rank(graph, personalized = V(graph)$department == i)$vector)
}

for (i in 1:45) {
  graph <- set_vertex_attr(graph, paste0("perpr_fg", i), value = page.rank(graph, personalized = V(graph)$membership_fg == i)$vector)
}


for (i in 1:32) {
  graph <- set_vertex_attr(graph, paste0("perpr_le", i), value = page.rank(graph, personalized = V(graph)$membership_le == i)$vector)
}

for (i in 1:136) {
  graph <- set_vertex_attr(graph, paste0("perpr_rw", i), value = page.rank(graph, personalized = V(graph)$membership_rw == i)$vector)
}


for (i in 1:26) {
  graph <- set_vertex_attr(graph, paste0("perpr_lv", i), value = page.rank(graph, personalized = V(graph)$membership_lv == i)$vector)
}
```


### Export the Features into a DataFrame:
Finally, we can export the features into a dataframe to use in predictive analysis:
```{r}
df_features <- igraph::as_data_frame(graph, what = "vertices")
df_features_train <- df_features %>% filter(department != -1)
df_features_test <- df_features %>% filter(department == -1)


write.csv(df_features_train, "./Data/train.csv", row.names=FALSE)
write.csv(df_features_test, "./Data/test.csv", row.names=FALSE)

```

